{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm import tqdm\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models.keyedvectors import WordEmbeddingsKeyedVectors\n",
    "from gensim.models import KeyedVectors\n",
    "\n",
    "from collections import Counter\n",
    "import sentencepiece as spm\n",
    "import re\n",
    "\n",
    "import distutils.dir_util\n",
    "import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_json(data, FILE_PATH, fname):\n",
    "    def _conv(o):\n",
    "        if isinstance(o, (np.int64, np.int32)):\n",
    "            return int(o)\n",
    "        raise TypeError\n",
    "\n",
    "    parent = os.path.dirname(fname)\n",
    "    distutils.dir_util.mkpath(FILE_PATH + parent)\n",
    "    with io.open(FILE_PATH + fname, \"w\", encoding=\"utf-8\") as f:\n",
    "        json_str = json.dumps(data, ensure_ascii=False, default=_conv)\n",
    "        f.write(json_str)\n",
    "\n",
    "def remove_seen(seen, l):\n",
    "    seen = set(seen)\n",
    "    return [x for x in l if not (x in seen)]\n",
    "\n",
    " \n",
    "def is_tag(word,tags_list_all):\n",
    "    if word in tags_list_all :\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "def before_updt_date(cand_song_idx,updt_date,song_meta):\n",
    "            \n",
    "    updt_date = int(re.sub('-','',updt_date)[:8])\n",
    "    return_idx = []\n",
    "    \n",
    "    for i in cand_song_idx:\n",
    "        if int(song_meta.loc[i,'issue_date'])>updt_date :\n",
    "            continue\n",
    "        else:\n",
    "            return_idx.append(i)\n",
    "\n",
    "    return return_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MakeAdditionalTags:\n",
    "    def __init__(self,FILE_PATH):\n",
    "        self.FILE_PATH = FILE_PATH\n",
    "        with open(os.path.join(FILE_PATH, 'genre_gn_all.json'), encoding=\"utf-8\") as f:\n",
    "            self.genre_gn_all = json.load(f)\n",
    "        self.res = []\n",
    "            \n",
    "\n",
    "    def mk_genre_tags (self,songs_input,song_meta, genre_gn_all, tag_num):\n",
    "        genre_list=[]\n",
    "        genre_tags_list=[]\n",
    "        \n",
    "        for i in songs_input:\n",
    "            genre_list+=song_meta.loc[i,'song_gn_gnr_basket']\n",
    "        c = Counter(genre_list)\n",
    "        genre_list=c.most_common(tag_num)\n",
    "        \n",
    "        for i in range(len(genre_list)):\n",
    "            try:genre_names = self.genre_gn_all[genre_list[i][0]].split('/')\n",
    "            except KeyError : continue\n",
    "            genre_tags_list += genre_names\n",
    "            \n",
    "        return genre_tags_list\n",
    "    \n",
    "    def sentence_piece (self,train):\n",
    "        titles_train = train[train['plylst_title'] != '']['plylst_title']\n",
    "\n",
    "        f = open('titles.txt', mode='wt', encoding='utf-8')\n",
    "        for i in titles_train : \n",
    "            f.write(re.sub(r'[^가-힣a-zA-Z0-9\\s]','',i)+'\\n')\n",
    "\n",
    "        for tags in train['tags']:\n",
    "            for tag in tags:\n",
    "                f.write(tag)\n",
    "                f.write(' ')\n",
    "            f.write('\\n')\n",
    "\n",
    "        f.close()\n",
    "\n",
    "        templates = '--input=titles.txt \\\n",
    "        --model_prefix=train \\\n",
    "        --vocab_size=20000 \\\n",
    "        --character_coverage=1.0 \\\n",
    "        --model_type=bpe \\\n",
    "        '\n",
    "\n",
    "        spm.SentencePieceTrainer.Train(templates)\n",
    "    \n",
    "    def mk_title_tags (self,data,tag_list_all):\n",
    "        sp = spm.SentencePieceProcessor()\n",
    "        sp.load('train.model')\n",
    "\n",
    "        sp_title = []\n",
    "        for i in tqdm(data['plylst_title']) :\n",
    "            i = re.sub(r'[^가-힣a-zA-Z0-9\\s]','',i)\n",
    "            if type(i) != str : sp_title.append([])\n",
    "            else:\n",
    "                pieces = sp.encode_as_pieces(i)\n",
    "                plus_tag = []\n",
    "                for i in pieces:\n",
    "                    tag = re.sub('▁','',i)\n",
    "\n",
    "                    if (len(tag) > 1) and (tag[-1] == '과' or tag[-1] == '와'):\n",
    "                        tag = tag[:-1]\n",
    "\n",
    "                    if is_tag(tag,tag_list_all):\n",
    "                        plus_tag.append(tag)\n",
    "                sp_title.append(plus_tag)\n",
    "\n",
    "        data['title_tags'] = sp_title\n",
    "    \n",
    "    def run (self,data,fname):\n",
    "        data['genre_tags'] = data.apply(lambda x : self.mk_genre_tags(x['songs'],song_meta,self.genre_gn_all,2),axis=1)\n",
    "        tags_list_all = []\n",
    "        for tags in train['tags']:\n",
    "            tags_list_all+=tags\n",
    "        for tags in val['tags']:\n",
    "            tags_list_all+=tags\n",
    "        tags_list_all = list(set(tags_list_all))\n",
    "        \n",
    "        self.mk_title_tags(data,tags_list_all)\n",
    "        \n",
    "\n",
    "        #태그 추가한 val.json 데이터 새로 쓰기\n",
    "        for pid in data.index:\n",
    "            self.res.append({\n",
    "                        \"tags\":data.loc[pid,\"tags\"],\n",
    "                        \"id\": data.loc[pid, \"id\"],\n",
    "                        \"songs\": data.loc[pid, \"songs\"],\n",
    "                        \"plylst_title\": data.loc[pid, \"plylst_title\"],\n",
    "                        \"like_cnt\": data.loc[pid, \"like_cnt\"],\n",
    "                        \"updt_date\": data.loc[pid, \"updt_date\"],\n",
    "                        \"genre_tags\": data.loc[pid, \"genre_tags\"],\n",
    "                        \"title_tags\": data.loc[pid, \"title_tags\"]\n",
    "                })\n",
    "\n",
    "        write_json(self.res, self.FILE_PATH, fname+'_addtags.json')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MakeBaselineResults:\n",
    "    \n",
    "    def __init__(self, FILE_PATH):\n",
    "        self.FILE_PATH = FILE_PATH\n",
    "        \n",
    "        with open(os.path.join(FILE_PATH, 'train_addtags.json'), encoding=\"utf-8\") as f:\n",
    "            self.train = pd.DataFrame(json.load(f))\n",
    "        \n",
    "        with open(os.path.join(FILE_PATH, 'val_addtags.json'), encoding=\"utf-8\") as f:\n",
    "            self.val = pd.DataFrame(json.load(f))\n",
    "               \n",
    "        with open(os.path.join(FILE_PATH, 'song_meta.json'), encoding=\"utf-8\") as f:\n",
    "            self.song_meta = pd.DataFrame(json.load(f))\n",
    "        \n",
    "        \n",
    "    \n",
    "    def intersect_cnt(self,tags,cand_tags,title_tags,genre_tags):\n",
    "        \n",
    "        tags_o = len(list(set(tags)&set(cand_tags))) * 3\n",
    "        tags_t = len(list(set(tags)&set(title_tags))) * 2\n",
    "        tags_g = len(list(set(tags)&set(genre_tags)))\n",
    "\n",
    "        score = tags_o+tags_t+tags_g\n",
    "\n",
    "        return score\n",
    "\n",
    "    def mk_rec_lack_of_songs(self, x):\n",
    "        t = pd.concat([self.train, self.val], ignore_index = True)\n",
    "        t['cnt'] = 0\n",
    "\n",
    "        tags_input = x.tags.copy()\n",
    "        tags_genre = x.genre_tags.copy()\n",
    "        tags_title = x.title_tags.copy()\n",
    "\n",
    "        tag_score = t['tags'].apply(lambda x : self.intersect_cnt(x,tags_input,tags_title,tags_genre))\n",
    "        t['cnt'] += tag_score\n",
    "\n",
    "\n",
    "        t = t.sort_values(by='cnt',ascending=False)\n",
    "\n",
    "        max_cnt = t.cnt.values[0]\n",
    "\n",
    "        tag_result = []\n",
    "        song_result = []\n",
    "\n",
    "        while max_cnt > 0  :\n",
    "\n",
    "            tl = list(t[t['cnt'] == max_cnt]['tags'])\n",
    "            sl = list(t[t['cnt'] == max_cnt]['songs'])\n",
    "\n",
    "            tc=Counter([item for sublist in tl for item in sublist]).most_common()\n",
    "            sc=Counter([item for sublist in sl for item in sublist]).most_common()\n",
    "            \n",
    "            #before updt_date인지 체크\n",
    "            cand_song = list(map(lambda x : x[0], sc))\n",
    "            song_result += before_updt_date(cand_song,x.updt_date,self.song_meta)\n",
    "\n",
    "            for i in tc:\n",
    "                if (i[0] not in x['tags']) & (i[0] not in tag_result):\n",
    "                    tag_result.append(i[0])\n",
    "            \n",
    "            song_result = remove_seen(x.songs, song_result)\n",
    "            tag_result = remove_seen(x.tags,tag_result)\n",
    "            \n",
    "            if ((len(song_result) >= 100) & (len(tag_result) >= 10)) :\n",
    "                break\n",
    "\n",
    "            max_cnt -= 1\n",
    "\n",
    "        return [tag_result[:10],song_result[:100]]\n",
    "    \n",
    "    def before_matrix_facotization(self,train,test):\n",
    "        train['istrain'] = 1\n",
    "        test['istrain'] = 0\n",
    "\n",
    "        n_train = len(train)\n",
    "        n_test = len(test)\n",
    "\n",
    "        # train + test\n",
    "        plylst = pd.concat([train, test], ignore_index=True)\n",
    "\n",
    "        # playlist id\n",
    "        plylst[\"nid\"] = range(n_train + n_test)\n",
    "\n",
    "        # id <-> nid    / 나중에 복구하기 위한 사전\n",
    "        plylst_id_nid = dict(zip(plylst[\"id\"],plylst[\"nid\"]))\n",
    "        plylst_nid_id = dict(zip(plylst[\"nid\"],plylst[\"id\"]))\n",
    "        \n",
    "        # 태그와 노래별로 인덱스를 새로 부여. 이후 다시 찾기 위한 사전 구성\n",
    "        # sparse matrix를 구성하기 위함.\n",
    "        plylst_tag = plylst['tags']\n",
    "        tag_counter = Counter([tg for tgs in plylst_tag for tg in tgs])\n",
    "        tag_dict = {x: tag_counter[x] for x in tag_counter}\n",
    "\n",
    "        tag_id_tid = dict()\n",
    "        tag_tid_id = dict()\n",
    "        for i, t in enumerate(tag_dict):\n",
    "            tag_id_tid[t] = i\n",
    "            tag_tid_id[i] = t\n",
    "\n",
    "        n_tags = len(tag_dict)\n",
    "\n",
    "        plylst_song = plylst['songs']\n",
    "        song_counter = Counter([sg for sgs in plylst_song for sg in sgs])\n",
    "        song_dict = {x: song_counter[x] for x in song_counter}\n",
    "\n",
    "        song_id_sid = dict()\n",
    "        song_sid_id = dict()\n",
    "        for i, t in enumerate(song_dict):\n",
    "            song_id_sid[t] = i\n",
    "            song_sid_id[i] = t\n",
    "\n",
    "        n_songs = len(song_dict)\n",
    "        \n",
    "        plylst['songs_id'] = plylst['songs'].map(lambda x: [song_id_sid.get(s) for s in x if song_id_sid.get(s) != None])\n",
    "        plylst['tags_id'] = plylst['tags'].map(lambda x: [tag_id_tid.get(t) for t in x if tag_id_tid.get(t) != None])\n",
    "\n",
    "        plylst_use = plylst[['istrain','nid','updt_date','songs_id','tags_id']]\n",
    "        plylst_use.loc[:,'num_songs'] = plylst_use['songs_id'].map(len)\n",
    "        plylst_use.loc[:,'num_tags'] = plylst_use['tags_id'].map(len)\n",
    "        plylst_use = plylst_use.set_index('nid')\n",
    "\n",
    "        plylst_train = plylst_use.iloc[:n_train,:]\n",
    "        plylst_test = plylst_use.iloc[n_train:,:]\n",
    "\n",
    "        row = np.repeat(range(n_train), plylst_train['num_songs'])\n",
    "        col = [song for songs in plylst_train['songs_id'] for song in songs]\n",
    "        dat = np.repeat(1, plylst_train['num_songs'].sum())\n",
    "\n",
    "        self.train_songs_A = spr.csr_matrix((dat, (row, col)), shape=(n_train, n_songs))\n",
    "\n",
    "        row = np.repeat(range(n_train), plylst_train['num_tags'])\n",
    "        col = [tag for tags in plylst_train['tags_id'] for tag in tags]\n",
    "        dat = np.repeat(1, plylst_train['num_tags'].sum())\n",
    "\n",
    "        self.train_tags_A = spr.csr_matrix((dat, (row, col)), shape=(n_train, n_tags))\n",
    "\n",
    "        # compressed sparse row로 만들기\n",
    "        self.train_songs_A_T = train_songs_A.T.tocsr()\n",
    "        self.train_tags_A_T = train_tags_A.T.tocsr()\n",
    "        \n",
    "        #test이름\n",
    "        test['songs_id'] = test['songs'].map(lambda x: [song_id_sid.get(s) for s in x if song_id_sid.get(s) != None])\n",
    "        test['tags_id'] = test['tags'].map(lambda x: [tag_id_tid.get(t) for t in x if tag_id_tid.get(t) != None])\n",
    "        \n",
    "        return test\n",
    "\n",
    "    def matrix_factorization_rec(self,pid):\n",
    "        res= []\n",
    "        for pid in tqdm(pids):\n",
    "\n",
    "            p = np.zeros((n_songs,1))\n",
    "            p[self.test.loc[pid,'songs_id']] = 1 #zero-vector에서 노래들의 인덱스를 1로 바꿈.\n",
    "\n",
    "            val = self.train_songs_A.dot(p).reshape(-1) #내적하여 1차원벡터로\n",
    "\n",
    "            # 노래 추천\n",
    "            songs_already = self.test.loc[pid, \"songs_id\"]\n",
    "            tags_already = self.test.loc[pid, \"tags_id\"]\n",
    "\n",
    "            cand_song = self.train_songs_A_T.dot(val) #val을 다시 내적\n",
    "\n",
    "            # 내림차순으로 \"인덱스\"를 정렬하고 역으로 상위 1000개 추출\n",
    "            cand_song_idx = cand_song.reshape(-1).argsort()[-1000:][::-1]\n",
    "\n",
    "            cand_song_idx = cand_song_idx[np.isin(cand_song_idx, songs_already) == False]\n",
    "\n",
    "            #plylst의 updt_date 이전 곡인가?\n",
    "            rec_song_idx = before_updt_date2(cand_song_idx,self.test.loc[pid,'updt_date'],self.song_meta)\n",
    "\n",
    "\n",
    "            # 태그 추천\n",
    "            cand_tag = self.train_tags_A_T.dot(val)\n",
    "            cand_tag_idx = cand_tag.reshape(-1).argsort()[-15:][::-1]\n",
    "\n",
    "            cand_tag_idx = cand_tag_idx[np.isin(cand_tag_idx, tags_already) == False][:10]\n",
    "            rec_tag_idx = [tag_tid_id[i] for i in cand_tag_idx]\n",
    "\n",
    "            res.append({\n",
    "                \"id\": self.test.loc[pid]['id'],\n",
    "                \"songs\": rec_song_idx,\n",
    "                \"tags\": rec_tag_idx\n",
    "            })    \n",
    "        return res\n",
    "    \n",
    "    def run(self):\n",
    "        tqdm.pandas()\n",
    "        \n",
    "        #song 개수가 3개 미만일 경우, makc_rec_lack_of_songs 모듈로, song 개수가 3개 이상일 경우 matrix_factorization 모듈로\n",
    "        \n",
    "        self.test_enough = self.test[(self.test.songs.str.len()>=3)].copy()\n",
    "        self.test_lack = self.test[(self.test.songs.str.len()<3)].copy()\n",
    "        \n",
    "        test_lack['rec'] = test_lack.progress_apply(lambda x : self.mk_rec_lack_of_songs(x),axis=1)\n",
    "        test_lack['rec_tags'] = test_lack.apply(lambda x : x.rec[0],axis=1)\n",
    "        test_lack['rec_songs'] = test_lack.apply(lambda x : x.rec[1],axis=1)\n",
    "        test_lack = test_lack.drop(columns='rec')\n",
    "        \n",
    "        \n",
    "        self.test_enough = before_matrix_facotization(self.train,self.test)\n",
    "        res = self.matrix_factorization_rec(self.test_enough.index)\n",
    "        self.test_enough['rec_tags'] = [i['tags'] for i in res]\n",
    "        self.test_enough['rec_songs'] = [i['songs'] for i in res]\n",
    "        \n",
    "        \n",
    "        self.answers = pd.concat([val_not, val_min]).sort_index(ascending=True)\n",
    "        \n",
    "        self.res = []\n",
    "        for pid in self.answers.index:\n",
    "            self.res.append({\n",
    "                    \"id\": self.val.loc[pid, \"id\"],\n",
    "                    \"songs\": self.val.loc[pid, \"rec_songs\"],\n",
    "                    \"tags\": self.val.loc[pid, \"rec_tags\"]\n",
    "            })\n",
    "        \n",
    "        write_json(self.res, self.FILE_PATH, \"base_results.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PlaylistEmbedding:\n",
    "    def __init__(self, FILE_PATH):\n",
    "        self.FILE_PATH = FILE_PATH\n",
    "        self.min_count = 3\n",
    "        self.size = 100\n",
    "        self.window = 210\n",
    "        self.sg = 5\n",
    "        \n",
    "        self.p2v_model = WordEmbeddingsKeyedVectors(self.size)\n",
    "        \n",
    "        with open(os.path.join(FILE_PATH, 'train.json'), encoding=\"utf-8\") as f:\n",
    "            self.train = json.load(f)\n",
    "        with open(os.path.join(FILE_PATH, 'val.json'), encoding=\"utf-8\") as f:\n",
    "            self.val = json.load(f)\n",
    "        with open(os.path.join(FILE_PATH, 'test.json'), encoding=\"utf-8\") as f:\n",
    "            self.test = json.load(f)  \n",
    "        with open(os.path.join(FILE_PATH, 'results.json'), encoding=\"utf-8\") as f:\n",
    "            self.most_results = json.load(f)\n",
    "    \n",
    "    # 전체 데이터에서 곡과 태그를 사전형식으로 저장\n",
    "    def get_dic(self, train, val, test):\n",
    "        song_dic = {}\n",
    "        tag_dic = {}\n",
    "        train = train + val\n",
    "        data = train + test\n",
    "\n",
    "        for q in tqdm(data):\n",
    "            song_dic[str(q['id'])] = q['songs']\n",
    "            tag_dic[str(q['id'])] = q['tags']\n",
    "        self.song_dic = song_dic\n",
    "        self.tag_dic = tag_dic\n",
    "        \n",
    "        # total = [['songs1'],['songs2'],['songs3'], ...['tags1'],['tags2'],[tags3]...]\n",
    "        total = list(map(lambda x: list(map(str, x['songs'])) + list(x['tags']), data))\n",
    "        total = [x for x in total if len(x)>1]\n",
    "        self.total = total\n",
    "        \n",
    "    def get_w2v(self, total, min_count, size, window, sg):\n",
    "        w2v_model = Word2Vec(total, min_count = min_count, size = size, window = window, sg = sg, workers = 4)\n",
    "        self.w2v_model = w2v_model\n",
    "        w2v_model.save(\"word2vec.model\")\n",
    "      \n",
    "    # 플레이리스트의 벡터값을 산출\n",
    "    def update_p2v(self, train, val, test, w2v_model):\n",
    "        train = train + val\n",
    "        ID = []   \n",
    "        vec = []\n",
    "        for q in tqdm(train + test):\n",
    "            tmp_vec = 0\n",
    "            if len(q['songs'])>=1:\n",
    "                for song in q['songs'] + q['tags']:\n",
    "                    try: \n",
    "                        tmp_vec += w2v_model.wv.get_vector(str(song))\n",
    "                    except KeyError:\n",
    "                        pass\n",
    "            if type(tmp_vec)!=int:\n",
    "                ID.append(str(q['id']))    \n",
    "                vec.append(tmp_vec)\n",
    "        self.p2v_model.add(ID, vec)\n",
    "        self.p2v_model.save('p2v_model.model')\n",
    "    \n",
    "    # 가장 비슷한 플레이리스트의 노래와 태그를 추천\n",
    "    def get_result(self, p2v_model, song_dic, tag_dic, most_results, test):\n",
    "        answers = []\n",
    "        for n, q in tqdm(enumerate(test), total = len(test)):\n",
    "            try:\n",
    "                most_id = [x[0] for x in p2v_model.most_similar(str(q['id']), topn=200)]\n",
    "                get_song = []\n",
    "                get_tag = []\n",
    "                for ID in most_id:\n",
    "                    get_song += song_dic[ID]\n",
    "                    get_tag += tag_dic[ID]\n",
    "                get_song = list(pd.value_counts(get_song)[:200].index)\n",
    "                get_tag = list(pd.value_counts(get_tag)[:20].index)\n",
    "                answers.append({\n",
    "                    \"id\": q[\"id\"],\n",
    "                    \"songs\": remove_seen(q[\"songs\"], get_song)[:100],\n",
    "                    \"tags\": remove_seen(q[\"tags\"], get_tag)[:10],\n",
    "                })\n",
    "            except:\n",
    "                answers.append({\n",
    "                  \"id\": most_results[n][\"id\"],\n",
    "                  \"songs\": most_results[n]['songs'],\n",
    "                  \"tags\": most_results[n][\"tags\"],\n",
    "                }) \n",
    "        # check and update answer\n",
    "        for n, q in enumerate(answers):\n",
    "            if len(q['songs'])!=100:\n",
    "                answers[n]['songs'] += remove_seen(q['songs'], self.most_results[n]['songs'])[:100-len(q['songs'])]\n",
    "            if len(q['tags'])!=10:\n",
    "                answers[n]['tags'] += remove_seen(q['tags'], self.most_results[n]['tags'])[:10-len(q['tags'])]  \n",
    "        self.answers = answers\n",
    "    \n",
    "    def run(self):\n",
    "        self.get_dic(self.train, self.val,self.test)\n",
    "        self.get_w2v(self.total, self.min_count, self.size, self.window, self.sg)\n",
    "        self.update_p2v(self.train, self.val, self.test, self.w2v_model)\n",
    "        self.get_result(self.p2v_model, self.song_dic, self.tag_dic, self.most_results, self.test)\n",
    "        \n",
    "        write_json(self.answers, 'results.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MAIN\n",
    "FILE_PATH = 'C:\\\\Users\\\\qorwl\\\\workingspace\\\\melon\\\\data\\\\' #train, val, test, song_meta, genre_gn_all이 저장되어 있는 디렉토리 경로로 변경\n",
    "\n",
    "train_tags = MakeAdditionalTags(FILE_PATH)\n",
    "train_tags.run(train,'train')\n",
    "val_tags = MakeAdditionalTags(FILE_PATH)\n",
    "val_tags.run(val,'val')\n",
    "test_tags= MakeAdditionalTags(FILE_PATH)\n",
    "test_tags.run(test,'test')\n",
    "\n",
    "base = MakeBaselineResults(FILE_PATH)\n",
    "results = base.run()\n",
    "\n",
    "U_space = PlaylistEmbedding(FILE_PATH)\n",
    "results = U_space.run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
